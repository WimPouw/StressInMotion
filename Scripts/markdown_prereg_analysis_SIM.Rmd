---
title: "Stress in Motion: Detailed Analysis Overview"
author: "Wim Pouw"
date: "5/28/2021"
output: html_document
---

```{r setup, echo=FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plotly)
library(RColorBrewer)
library(wesanderson)
library(ggbeeswarm)
library(papaja)
library(nlme)
library(plyr)
library(lsmeans)
library(tidyr)
library(EMAtools)

curfolder <- getwd()
D <- read.csv(paste0(dirname(curfolder), "/ProcessedTimingData/DD.csv"))
D <- na.omit(D)

D$accent  <- ifelse(D$accent=="yes", "accent present", "no accent")
D$accent  <- factor(D$accent, levels=c("no accent", "accent present"))
D$correct <- factor(D$correct, levels=c("L2 correct", "L2 incorrect & L1 match", "L2 incorrect & L1 mismatch"))
D$stress <-  factor(D$stress, levels=c("same", "difference"))
D$condition <-  factor(D$condition, levels=c("nogesture", "gesture"))
```

## Goal of this Rmarkdown document

This Rmarkdown notebook contains a detailed documentation of how the analysis will be performed, provided with R code when informative. It not only contains the statistical model codes, but also the results they produce when applied to the pilot data. At the end of the section we report on a power analysis, providing some insights on how many participants we need to test.

## Main Research Questions

Each of the analysis are tailored to provide statistically informed conclusions about the following research questions:

* 1. Does the production of a gesture by Dutch learners of Spanish improve their L2 acoustic stress placement (i.e., are they more likely to stress the L2 target syllable)? (confirmatory)

* 2. Does the production of a gesture by Dutch learners of Spanish affect their acoustic markers of L2 stress production (i.e., do they mark prominence more saliently)? (confirmatory)

* 3. When L2 stress placement is especially taxing (i.e., when stress is orthographically marked and/or there is an L1/L2 stress mismatch), is gesture-speech synchrony affected? (confirmatory)
** 3a. If lexical stress in L2 is incorrectly placed, is the timing of gesture still temporally attracted to the L2 target? (exploratory)
** 3b. If lexical stress in L2 is correctly placed, is the timing of gesture still temporally attracted to the L1 target?  (exploratory)

## Initial descriptive checks of the data

Here we provide a descriptive overview of the syllable identifications relative to target (table 1). In the current pilot data the number of syllables identified by EasyAlign perfectly matched the targeted number of syllables, i.e., in 100% of the trials there were 0 differences in the number of syllable detected versus target.

```{r table01, echo= FALSE, warning = FALSE, message = FALSE}
tab01 <- data.frame(prop.table(table(D$Nsyllables-D$Nsyllables_correct))*100)
colnames(tab01) <- c("syllable differences", "percentage")  
  
apa_table(
  tab01
  , align = c("l", rep("r", 3))
  , caption = "Table 1. A summary table of percentage of differences between syllables"
)
```

Table 2 provides the percentages of different type of L2 stress placement matches and mismatches.

```{r table02, echo = FALSE}
tab02 <- data.frame(prop.table(table(D$correct, D$stress))*100)
colnames(tab02) <- c("stress mis/match type", "stress difference", "percentage")  
  
  
apa_table(
  tab02
  , align = c("l", rep("r", 3))
  , caption = "Table 2. A summary table of percentage of stress match/mismatch types"
)
```

## Main Confirmatory Analysis

For all analysis we will use mixed linear regressions with maximum likelihood estimation using R-package nlme. Our models will always have participant and trial ID as random variables. We will always try to fit random slopes, next to random intercepts. With the current pilot data however, adding random slopes resulted in non-converging models. Thus for all models reported we have participant and trial ID as random intercepts. We further report a Cohen's *D* for our model predictors using R-package EMAtools. For interaction effects we will follow up with a post-hoc contrast analysis using R-package lsmeans, and we apply a Bonferroni correction for such multiple comparison tests.

## Research question 1:  Effect of gesture on stress timing  
  For the first analysis we simply assess whether the absolute difference in directional stress timing is different for the gesture versus no gesture condition, while also accounting for effects on timing due to stress L1/L2 difference and accentedness. If gesture improves stress timing, lower absolutized stress timings are to be expected (i.e., lower deviances from perfect synchrony).

Figure 3 upper panel. Effect of gesture versus no gesture on stress timing
```{r, echo = FALSE}
#stress correct
a <- ggplot(D, aes(x= stressed_mistimingL2L1, color = condition)) + geom_density(size= 2, alpha = 0.75)+theme_bw()+ylim(1e-12, NA)+ xlab("L2 <- Directional Stress timing -> L1")+geom_vline(xintercept = 0, color = "black")
a <- a + scale_color_manual(values=wes_palette(n=2, name = "Royal1"))
ggplotly(a)
```
  
  We first construct a base model predicting the overall mean, with participant and trial ID random variables, and absolute stress timing as the dependent variable. This model is then compared to a model with stress difference + accentedness + gesture condition as main effects.  

Code chunk 1. Model research question 1
```{r}
D$accuracy <- abs(D$stressed_mistimingL2L1) #absolute deviation stress timing

#basemodel predicting the overall mean stress timing
model0 <- lme(accuracy~1, data = D, random = list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)

#alternative model with, stress, accentedness, and gesture versus no gesture as predictors
model1 <- lme(accuracy~stress+accent+condition, data = D, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)
anovcomp01 <- anova(model0, model1) #test difference basemodel versus model 1
sum1 <- summary(model1) 
Dmod1 <- lme.dscore(model1, D, type="nlme")


```
  
  <details><summary>Click here for model 1 R output</summary>
    ```{r, eval=TRUE}
    model1
    sum1
    Dmod1
    ```
  </details>

  <details><summary>Click here for model 1 summary</summary>
  
  In our pilot data, the model with stress, accentedness, and gesture conditions as predictors outperformed the base model, change in Chi-sq (3) = `r printnum(anovcomp01$L.Ratio[2], digits= 3)`, *p* = `r printnum(anovcomp01$'p-value'[2],  digits=3 )`. The models results indicate a statistically reliable main effect of gesture vs. no gesture, *b* = `r printnum(sum1$tTable[4,1],  digits=4 )`, *t* (`r printnum(sum1$tTable[4,3], digits=0 )`) = `r printnum(sum1$tTable[4,4],  digits=4 )`, *p* = `r printnum(sum1$tTable[4,5],  digits=3 )`, Cohen's *D* = `r printnum(round(Dmod1$d[3],  digits=3))`. Stress difference was not a reliable  main effect, *b* = `r printnum(sum1$tTable[2,1],  digits=3 )`, *t* (`r printnum(sum1$tTable[2,3], digits=0 )`) = `r printnum(sum1$tTable[2,4], digits= 4 )`, *p* = `r printnum(sum1$tTable[2,5],  digits=3 )`, Cohen's *D* = `r printnum(Dmod1$d[1], digits = 3)`. Accent was not a reliable main effect, *b* = `r printnum(sum1$tTable[3,1],  digits=4 )`, *t* (`r printnum(sum1$tTable[3,3],  digits=0 )`) = `r printnum(sum1$tTable[3,4],  digits=3 )`, *p* = `r printnum(sum1$tTable[3,5],  digits=3 )`, Cohen's *D* = `r printnum(Dmod1$d[2],  digits=3)`.
  </details>
    
Figure 3 lower panels. Effect of gesture versus no gesture ~ stress and accent
```{r, echo = FALSE}
#stress correct
a <- ggplot(D, aes(x= stressed_mistimingL2L1, color = condition)) + geom_density(size= 2, alpha = 0.75)+theme_bw()+ylim(1e-12, NA)+facet_grid(.~stress)
a <- a + scale_color_manual(values=wes_palette(n=2, name = "Royal1")) + xlab("L2 <- Directional Stress timing -> L1") + ggtitle("effect gesture vs. no gesture ~ stress difference")+geom_vline(xintercept = 0, color = "black")
ggplotly(a)

#stress correct
a <- ggplot(D, aes(x= stressed_mistimingL2L1, color = condition)) + geom_density(size= 2, alpha = 0.75)+theme_bw()+ylim(1e-12, NA)+facet_grid(.~accent)
a <- a + scale_color_manual(values=wes_palette(n=2, name = "Royal1"))+ xlab("L2 <- Directional Stress timing -> L1")  + ggtitle("effect gesture vs. no gesture ~ accent")+geom_vline(xintercept = 0, color = "black")
ggplotly(a)
```

We will further assess this in a complex model we expand our analysis with the relevant stimuli conditions, as well as their interactions with the gesture condition. If the interactions are statistically reliable we will perform a post-hoc comparisons with R-package "lsmeans" with a bonferroni correction.

Code chunk 2. Model research question 1, with three way interaction
```{r, eval = TRUE}
#alternative model with gesture versus no gesture as predictor
model2 <- lme(accuracy~condition*stress*accent, 
              data = D, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)

anova(model1, model2) #test difference basemodel versus model 1

#summary model 3 post hoc
sum3 <- summary(model2)
posthoc3 <- lsmeans(model2, list(pairwise ~ condition|accent|stress),  adjust="bonferroni")
```

<details><summary>Click here for model 3 summary</summary>
    ```{r, eval=TRUE}
    sum3
    ```
</details>
<details><summary>Click here for posth-hoc3 output</summary>
    ```{r, eval=TRUE}
    posthoc3
    ```
</details>

## Prosodic modulation of gesture

Does gesture vs. no gesture affect acoustic markers of stress? We perform a mixed linear regression with normalized acoustic markers as DV, and acoustic marker (peak F0, peak envelope, and duration) x condition as independent variable. 


Figure 4. Effect of gesture vs. no gesture on acoustic markers of stress 
```{r, echo = FALSE, message= FALSE, warning = FALSE, fig.width = 7}
a <- ggplot(D, aes(x = condition, y = D$peakF0z, color = condition)) + geom_quasirandom(alpha=0.2) + geom_boxplot(alpha = 0, color = "black") + scale_color_manual(values=wes_palette(n=2, name = "Royal1"))+ylab("peak F0 (normalized)")+theme_bw()+theme(legend.position = "none")+ theme(axis.text.x=element_text(angle = -70, hjust = 0))
b <- ggplot(D, aes(x = condition, y = D$peakAMPz, color = condition)) + geom_quasirandom(alpha=0.2) + geom_boxplot(alpha = 0, color = "black") + scale_color_manual(values=wes_palette(n=2, name = "Royal1"))+ylab("peak envelope (normalized)")+theme_bw()+theme(legend.position = "none")+ theme(axis.text.x=element_text(angle = -70, hjust = 0))
c <- ggplot(D, aes(x = condition, y = D$sDURz, color = condition)) + geom_quasirandom(alpha=0.2) + geom_boxplot(alpha = 0, color = "black") + scale_color_manual(values=wes_palette(n=2, name = "Royal1"))+ylab("vocal duration (normalized)")+theme_bw()+theme(legend.position = "none")+ theme(axis.text.x=element_text(angle = -70, hjust = 0))
d <- ggplot(D, aes(x = condition, y = stressSCORE, color = condition)) + geom_quasirandom(alpha=0.2) + geom_boxplot(alpha = 0, color = "black") + scale_color_manual(values=wes_palette(n=2, name = "Royal1"))+ylab("stress score (normalized)")+theme_bw()+theme(legend.position = "none")+ theme(axis.text.x=element_text(angle = -70, hjust = 0))

subplot(ggplotly(a), ggplotly(b), ggplotly(c), ggplotly(d), titleY = TRUE,margin = 0.04)

```

Code chunk 3. Gesture and acoustic output
```{r, eval = TRUE, warning = FALSE}
Dlong <- gather(D, "marker", "acoust_out", 13:15)

#alternative model with gesture versus no gesture as predictor
model0 <- lme(acoust_out~1, data = Dlong, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)
model1 <- lme(acoust_out~marker*condition, data = Dlong, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)
anova(model0, model1) #test difference basemodel versus model 1

#summary model 3 post hoc
anovamod0mod1 <- anova(model0, model1)
sum1 <- summary(model1)
posthocsum1 <- lsmeans(model1, list(pairwise ~ condition|marker),  adjust="bonferroni")
Dmod1 <- lme.dscore(model1, Dlong, type="nlme")

```
<details><summary>Click here for model 1 R output</summary>
    ```{r, eval=TRUE}
    sum1
    ```
</details>

<details><summary>Click here for model 1 summary for research question 2</summary>

  Does gesture vs. no gesture affect acoustic markers of stress? We perform a mixed linear regression with normalized acoustic output as DV, and acoustic marker (peak F0z, peak envelope, and duration) x condition as independent variable. We again test this model against a base model predicting the overall mean.  
  The model with acoustic markers x condition was a more reliable model than the base model predicting the overall mean of the acoustic output, Chi-sq (5) = `r printnum(anovamod0mod1$L.Ratio[2], digits = 3)`, *p* = `r printnum(anovamod0mod1$'p-value'[2], digits = 3)`. Table 3 provides an overview of the model predictors.
  
```{r table03, echo = FALSE}
tab03 <- cbind.data.frame(sum1$tTable, c(NA, Dmod1$d))
  
  
apa_table(
  tab03
  , caption = "Table 3. Model fitted predictions"
)
```

  We will further perform a post-hoc analysis disentangling these interaction effects, where we assess for which acoustic marker gesture vs. no gesture affected acoustic output. 
</details>

<details><summary>Click here for posthoc model 1 output</summary>
    ```{r, eval=TRUE}
    posthocsum1
    ```
</details>

</details> 

## Research question 3: Gesture-speech asynchrony as a function of trial conditions

From the previous analyses we should know whether stress timing performance and acoustic stress marking increases or decreases as a function of gesture, as well as the possible role of stress difference, and accentedness in stress timing. A further question is whether the timing between gesture and speech is affected by stress difference and accentedness, which would signal that gesture does not simply always synchronize with speech, but that coordination is destabilized due to difficulties of reaching the L2 targets without orthographic cues or with L1 stress competitor.  
	Using a similar linear mixed modeling approach as the previous analysis we compare a base model with models with stress difference and accentedness (and their possible interactions) as predictors for the absolutized gesture-speech asynchrony. 

Figure 5. Gesture-speech (a)synchrony depending on stress difference and accentedness
```{r, echo = FALSE}
subD <- subset(D, condition == "gesture")
a <- ggplot(subD, aes(x= asynchrony, color = stress)) + geom_density(size= 2)+theme_bw()+ylim(1e-12, NA)+facet_grid(.~accent)
a <- a + scale_color_manual(values=wes_palette(n=2, name = "BottleRocket2")) + ggtitle("asynchrony as a function of stress difference and accent")
ggplotly(a)
```

    ```{r, echo=FALSE, eval=TRUE}
subD$abs_asynchrony <- abs(subD$asynchrony)
#alternative model with gesture versus no gesture as predictor
model0 <- lme(abs_asynchrony~1, data = subD, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)
model1 <- lme(abs_asynchrony~stress+accent, data = subD, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)
model2 <- lme(abs_asynchrony~stress*accent, data = subD, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)

anovmod01 <- anova(model0, model1) #test difference basemodel versus model 1
anovmod02 <- anova(model0, model2) #test difference basemodel versus model 1

#if interaction effects are reliable we will follow up with post-hocs
sum1 <- summary(model1)
sum2 <- summary(model2)
posthoc2 <- lsmeans(model2, list(pairwise ~ stress|accent),  adjust="bonferroni")
Dmod1 <- lme.dscore(model1, subD, type="nlme")

```


<details><summary>Click here for posthoc model 1 and 2 output</summary>
    ```{r, eval=TRUE}
    sum1
    sum2
    posthoc2
    ```
</details>

<details><summary>Click here for model 2 summary for research question 3</summary>

 For our pilot data, including stress difference and accentedness as predictors in an alternative model was not a more reliable than the base model predicting the overall mean of the absolutized gesture-speech (a)synchrony, Chi-sq (2) = `r printnum(anovmod01$L.Ratio[2], digits = 3)`, *p* = `r printnum(anovmod01$'p-value'[2], digits = 3)`, and adding interactions between stress difference and accentedness also did not further improve  predictions of gesture-speech asynchrony, Chi-sq (3) = `r printnum(anovmod02$L.Ratio[2], digits = 3)`, *p* = `r printnum(anovmod02$'p-value'[2], digits = 3)`. Table 4 provides an overview of the model predictors for the model without interactions.
  
```{r table04, echo = FALSE}
tab04 <- cbind.data.frame(sum1$tTable, c(NA, Dmod1$d))
  
apa_table(
  tab04
  , caption = "Table 4. Model fitted predictions"
)
```

</details>


## Gesture-speech asynchrony and the directionality of error

From the previous analysis we will know if gesture-speech synchrony can be affected by trial conditions that may complicate correct stress placement. If indeed gesture-speech synchrony is affected, we can wonder about how gesture and speech diverge when they are more asynchronous.

```{r, echo = FALSE}
#for correct placement
Dsub <- subset(D, condition != "gesture")
a <- ggplot(Dsub, aes(x = stress, y= asynchrony_L2L1))+geom_hline(yintercept = 0, color = "red", size = 0.5)+geom_violin(fill=NA) + geom_quasirandom(color = "black", size = 0.7, alpha = 0.5)+geom_boxplot(alpha = 0)+theme_bw() + coord_flip()
a <- a +facet_grid(correct~.)
ggplotly(a)
```


```{r}
#basemodel predicting the overall mean accuracy
model0 <- lme(asynchrony_L2L1~1, data = subD, random = list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)

#alternative model with gesture versus no gesture as predictor
model1 <- lme(asynchrony_L2L1~stress*correct, data = subD, random =  list(~1|ppn, ~1|target), method = "ML", na.action = na.exclude)
anova(model0, model1) #test difference basemodel versus model 1
summary(model1) 
```


## Power analysis
  To provide some indication on the amount of data we need to collect to get meaningful results, we will perform a power analysis concerning the first research question. We will assess a complex three way interaction model, and identify how many subjects we need to detect a main and interaction effects including gesture condition at a power of 80%. We use R-package mixedpower to determine this 

```{r, eval = FALSE, cache = TRUE}
#for details on this power analysis see
https://link.springer.com/article/10.3758/s13428-021-01546-0

# load library
library(mixedpower)
library(doParallel)
#main DV of interest
D$accuracy <- abs(D$stressed_mistimingL2L1) #absolute deviation from stress from L2
D$ppn <- as.numeric(as.factor(D$ppn)) #random variable to extend 

#lme4 model instead of lme
model1 <- lmer(accuracy~accent+stress+condition +(1|ppn) + (1|target), data = D, na.action = na.exclude)


```

